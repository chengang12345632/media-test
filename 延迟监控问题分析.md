# 延迟监控问题分析与修复方案

## 问题描述

1. **直通延迟监控正常** ✅
2. **MP4回放没有延迟监控** ❌
3. **H.264回放延迟监控功能不正常** ❌

## 问题根因分析

### 1. MP4回放没有延迟监控

**根本原因**：在 `handler.rs` 的转发任务中，延迟监控的时间戳记录存在问题：

```rust
// 当前代码（第378-380行）
let device_send_time = receive_time; // 使用接收时间作为近似值
latency_monitor.record_device_send(segment.segment_id, device_send_time);
latency_monitor.record_platform_receive(segment.segment_id, receive_time);
```

**问题**：
- 对于回放场景，`device_send_time` 和 `receive_time` 是同一个时间
- 这导致传输延迟（T2-T1）始终为0
- 回放的 `segment.timestamp` 是相对时间戳（从0开始），不是绝对时间
- 没有真实的设备发送时间，导致延迟监控数据不准确

### 2. H.264回放延迟监控不正常

**根本原因**：
- H.264回放使用 `PlaybackSource`，它的 `next_segment()` 方法没有设置 `segment.receive_time`
- 在 `handler.rs` 中虽然有兜底逻辑设置 `receive_time`，但这个时间是在handler中设置的，不是在source中
- 对于回放场景，应该使用分片读取时间作为"设备发送时间"的模拟

### 3. 前端缺少客户端播放时间记录

**根本原因**：
- 前端播放器（`UnifiedMSEPlayer.tsx` 和 `WebCodecsPlayer.tsx`）没有调用 `record_client_play` API
- 缺少 T4 时间戳，导致无法计算完整的端到端延迟
- 只能计算平台内部的处理延迟，无法计算分发延迟和端到端延迟

## 修复方案

### 方案1：区分直通和回放的延迟监控逻辑

#### 1.1 在 `VideoSegment` 中添加来源标识

```rust
pub struct VideoSegment {
    // ... 现有字段
    pub source_type: SegmentSourceType, // 新增
}

pub enum SegmentSourceType {
    Live,      // 直通播放
    Playback,  // 回放
}
```

#### 1.2 修改 `handler.rs` 的延迟记录逻辑

```rust
// 根据来源类型决定如何记录延迟
match segment.source_type {
    SegmentSourceType::Live => {
        // 直通播放：使用真实的设备发送时间
        let device_send_time = segment.receive_time.unwrap_or(receive_time);
        latency_monitor.record_device_send(segment.segment_id, device_send_time);
        latency_monitor.record_platform_receive(segment.segment_id, receive_time);
    }
    SegmentSourceType::Playback => {
        // 回放：使用分片读取时间作为"设备发送时间"
        // 这样可以测量从文件读取到转发的延迟
        let read_time = segment.receive_time.unwrap_or(receive_time);
        latency_monitor.record_device_send(segment.segment_id, read_time);
        latency_monitor.record_platform_receive(segment.segment_id, receive_time);
    }
}
```

#### 1.3 修改 `PlaybackSource` 设置 `receive_time`

```rust
// 在 playback_source.rs 的 next_segment() 方法中
async fn next_segment(&mut self) -> Result<Option<VideoSegment>, StreamError> {
    // ... 现有代码
    
    match self.file_reader.read_segment().await {
        Ok(Some(mut segment)) => {
            // 设置接收时间（实际是读取时间）
            segment.receive_time = Some(SystemTime::now());
            segment.source_type = SegmentSourceType::Playback; // 标记为回放
            
            // ... 其余代码
            Ok(Some(segment))
        }
        // ...
    }
}
```

### 方案2：前端添加客户端播放时间记录

#### 2.1 添加 API 调用函数

在 `web-frontend/src/services/api.ts` 中添加：

```typescript
export const recordClientPlayTime = async (
  segmentId: string,
  playTime: number
): Promise<void> => {
  await fetch(`${API_BASE_URL}/api/v1/latency/segments/${segmentId}/play`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ play_time: playTime })
  });
};
```

#### 2.2 在播放器中记录播放时间

在 `UnifiedMSEPlayer.tsx` 中：

```typescript
// 在 sourceBuffer.appendBuffer 之后
sourceBuffer.addEventListener('updateend', () => {
  // 记录客户端播放时间
  const playTime = Date.now();
  recordClientPlayTime(segmentId, playTime).catch(console.error);
});
```

在 `WebCodecsPlayer.tsx` 中：

```typescript
// 在 decoder.decode(chunk) 之后
decoder.decode(chunk);

// 记录客户端播放时间
const playTime = Date.now();
recordClientPlayTime(segmentId, playTime).catch(console.error);
```

#### 2.3 后端添加 API 端点

在 `platform-server/src/http3/latency_handlers.rs` 中添加：

```rust
#[derive(Deserialize)]
pub struct ClientPlayTimeRequest {
    play_time: u64, // Unix timestamp in milliseconds
}

pub async fn record_client_play_time(
    Path(segment_id): Path<String>,
    State(state): State<LatencyAppState>,
    Json(req): Json<ClientPlayTimeRequest>,
) -> Json<ApiResponse<String>> {
    let segment_id = match Uuid::parse_str(&segment_id) {
        Ok(id) => id,
        Err(_) => return Json(ApiResponse::error("Invalid segment ID")),
    };
    
    let play_time = SystemTime::UNIX_EPOCH + Duration::from_millis(req.play_time);
    
    let (monitor, _, _) = state;
    monitor.record_client_play(segment_id, play_time);
    
    Json(ApiResponse::success("Client play time recorded".to_string()))
}
```

### 方案3：简化方案（推荐）

考虑到回放场景的特殊性，我们可以采用更简单的方案：

#### 3.1 只监控平台内部延迟

对于回放场景，只监控：
- **处理延迟**：从文件读取到转发的时间（T3-T2）
- **分发延迟**：从转发到客户端播放的时间（T4-T3）

不监控传输延迟（因为没有真实的设备传输）

#### 3.2 修改代码实现

```rust
// 在 handler.rs 中
match segment.source_type {
    SegmentSourceType::Live => {
        // 直通：记录完整的延迟链路
        latency_monitor.record_device_send(segment.segment_id, device_send_time);
        latency_monitor.record_platform_receive(segment.segment_id, receive_time);
        latency_monitor.record_platform_forward(segment.segment_id, forward_time);
    }
    SegmentSourceType::Playback => {
        // 回放：只记录平台内部延迟
        // 使用 receive_time 作为起点
        latency_monitor.record_platform_receive(segment.segment_id, receive_time);
        latency_monitor.record_platform_forward(segment.segment_id, forward_time);
        // 不记录 device_send，避免误导性的0延迟
    }
}
```

## 推荐实施步骤

1. **第一步**：修改 `VideoSegment` 添加 `source_type` 字段
2. **第二步**：修改 `PlaybackSource` 设置 `receive_time` 和 `source_type`
3. **第三步**：修改 `handler.rs` 区分直通和回放的延迟记录逻辑
4. **第四步**：前端添加客户端播放时间记录（可选，用于完整的端到端监控）
5. **第五步**：测试验证

## 预期效果

修复后：
- ✅ 直通播放：完整的端到端延迟监控（T1→T2→T3→T4）
- ✅ MP4回放：平台内部延迟监控（T2→T3→T4）
- ✅ H.264回放：平台内部延迟监控（T2→T3→T4）
- ✅ 延迟统计和告警正常工作
